2021-02-07 16:01:31,743 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2021-02-07 16:01:31,749 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Starting YarnApplicationClusterEntryPoint (Version: 1.11.2, Scala: 2.11, Rev:fe36135, Date:2020-09-09T16:19:03+02:00)
2021-02-07 16:01:31,749 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  OS current user: yarn
2021-02-07 16:01:32,088 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Current Hadoop/Kerberos user: deploy
2021-02-07 16:01:32,088 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM: Java HotSpot(TM) 64-Bit Server VM - Oracle Corporation - 1.8/25.141-b15
2021-02-07 16:01:32,088 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Maximum heap size: 429 MiBytes
2021-02-07 16:01:32,088 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JAVA_HOME: /usr/java/jdk1.8.0_141-cloudera
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Hadoop version: 2.4.1
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM Options:
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xmx469762048
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xms469762048
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -XX:MaxMetaspaceSize=268435456
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog.file=/data1/yarn/container-logs/application_1612516048266_0657/container_e111_1612516048266_0657_01_000001/jobmanager.log
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configuration=file:log4j.properties
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configurationFile=file:log4j.properties
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Program Arguments: (none)
2021-02-07 16:01:32,090 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Classpath: :lib/commons-logging-1.1.3.jar:lib/commons-pool2-2.4.2.jar:lib/flink-avro-1.11.2-sql-jar.jar:lib/flink-connector-adb-jdbc_2.11-1.0-SNAPSHOT.jar:lib/flink-connector-jdbc_2.11-1.11.2.jar:lib/flink-connector-kafka-0.10_2.11-1.11.2.jar:lib/flink-connector-kafka-0.11_2.11-1.11.2.jar:lib/flink-connector-kafka-base_2.11-1.11.2.jar:lib/flink-connector-kudu_2.11-1.0-SNAPSHOT.jar:lib/flink-connector-redis_2.11-1.0-SNAPSHOT.jar:lib/flink-csv-1.11.2.jar:lib/flink-json-1.11.2.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-1.2.2_2.11-1.11.2.jar:lib/flink-sql-orc_2.11-1.11.2.jar:lib/flink-sql-parquet_2.11-1.11.2.jar:lib/flink-table-blink_2.11-1.11.2.jar:lib/flink-table_2.11-1.11.2.jar:lib/hbase-connector/flink-connector-hbase_2.11-1.11.1.jar:lib/hbase-connector/lib/akka-actor_2.11-2.5.21.jar:lib/hbase-connector/lib/akka-protobuf_2.11-2.5.21.jar:lib/hbase-connector/lib/akka-slf4j_2.11-2.5.21.jar:lib/hbase-connector/lib/akka-stream_2.11-2.5.21.jar:lib/hbase-connector/lib/aopalliance-1.0.jar:lib/hbase-connector/lib/asm-3.1.jar:lib/hbase-connector/lib/audience-annotations-0.5.0.jar:lib/hbase-connector/lib/avatica-core-1.16.0.jar:lib/hbase-connector/lib/avro-1.8.2.jar:lib/hbase-connector/lib/byte-buddy-1.8.15.jar:lib/hbase-connector/lib/byte-buddy-agent-1.8.15.jar:lib/hbase-connector/lib/chill-java-0.7.6.jar:lib/hbase-connector/lib/chill_2.11-0.7.6.jar:lib/hbase-connector/lib/commons-beanutils-1.8.3.jar:lib/hbase-connector/lib/commons-cli-1.3.1.jar:lib/hbase-connector/lib/commons-codec-1.10.jar:lib/hbase-connector/lib/commons-collections-3.2.2.jar:lib/hbase-connector/lib/commons-compiler-3.0.9.jar:lib/hbase-connector/lib/commons-compress-1.20.jar:lib/hbase-connector/lib/commons-configuration-1.7.jar:lib/hbase-connector/lib/commons-daemon-1.0.13.jar:lib/hbase-connector/lib/commons-digester-1.8.1.jar:lib/hbase-connector/lib/commons-el-1.0.jar:lib/hbase-connector/lib/commons-httpclient-3.1.jar:lib/hbase-connector/lib/commons-io-2.4.jar:lib/hbase-connector/lib/commons-lang-2.6.jar:lib/hbase-connector/lib/commons-lang3-3.3.2.jar:lib/hbase-connector/lib/commons-logging-1.1.3.jar:lib/hbase-connector/lib/commons-math-2.2.jar:lib/hbase-connector/lib/commons-math3-3.5.jar:lib/hbase-connector/lib/commons-net-3.1.jar:lib/hbase-connector/lib/config-1.3.0.jar:lib/hbase-connector/lib/curator-test-2.12.0.jar:lib/hbase-connector/lib/disruptor-3.4.2.jar:lib/hbase-connector/lib/findbugs-annotations-1.3.9-1.jar:lib/hbase-connector/lib/force-shading-1.11.1.jar:lib/hbase-connector/lib/grizzled-slf4j_2.11-1.3.2.jar:lib/hbase-connector/lib/guava-11.0.2.jar:lib/hbase-connector/lib/guice-3.0.jar:lib/hbase-connector/lib/guice-servlet-3.0.jar:lib/hbase-connector/lib/hadoop-annotations-2.4.1.jar:lib/hbase-connector/lib/hadoop-auth-2.4.1.jar:lib/hbase-connector/lib/hadoop-client-2.7.4.jar:lib/hbase-connector/lib/hadoop-common-2.4.1-tests.jar:lib/hbase-connector/lib/hadoop-common-2.4.1.jar:lib/hbase-connector/lib/hadoop-hdfs-2.4.1-tests.jar:lib/hbase-connector/lib/hadoop-hdfs-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-app-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-common-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-core-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-hs-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-jobclient-2.4.1-tests.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-jobclient-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-shuffle-2.4.1.jar:lib/hbase-connector/lib/hadoop-minicluster-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-api-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-client-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-common-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-applicationhistoryservice-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-common-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-nodemanager-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-resourcemanager-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-tests-2.4.1-tests.jar:lib/hbase-connector/lib/hadoop-yarn-server-web-proxy-2.4.1.jar:lib/hbase-connector/lib/hamcrest-all-1.3.jar:lib/hbase-connector/lib/hamcrest-core-1.3.jar:lib/hbase-connector/lib/hbase-annotations-1.4.3.jar:lib/hbase-connector/lib/hbase-client-1.4.3.jar:lib/hbase-connector/lib/hbase-common-1.4.3-tests.jar:lib/hbase-connector/lib/hbase-common-1.4.3.jar:lib/hbase-connector/lib/hbase-hadoop-compat-1.4.3-tests.jar:lib/hbase-connector/lib/hbase-hadoop-compat-1.4.3.jar:lib/hbase-connector/lib/hbase-hadoop2-compat-1.4.3-tests.jar:lib/hbase-connector/lib/hbase-hadoop2-compat-1.4.3.jar:lib/hbase-connector/lib/hbase-metrics-1.4.3.jar:lib/hbase-connector/lib/hbase-metrics-api-1.4.3.jar:lib/hbase-connector/lib/hbase-prefix-tree-1.4.3.jar:lib/hbase-connector/lib/hbase-procedure-1.4.3.jar:lib/hbase-connector/lib/hbase-protocol-1.4.3.jar:lib/hbase-connector/lib/hbase-server-1.4.3-tests.jar:lib/hbase-connector/lib/hbase-server-1.4.3.jar:lib/hbase-connector/lib/htrace-core-3.1.0-incubating.jar:lib/hbase-connector/lib/httpclient-4.5.3.jar:lib/hbase-connector/lib/httpcore-4.4.6.jar:lib/hbase-connector/lib/jackson-core-asl-1.8.8.jar:lib/hbase-connector/lib/jackson-jaxrs-1.9.13.jar:lib/hbase-connector/lib/jackson-mapper-asl-1.8.8.jar:lib/hbase-connector/lib/jackson-xc-1.8.3.jar:lib/hbase-connector/lib/jamon-runtime-2.4.1.jar:lib/hbase-connector/lib/janino-3.0.9.jar:lib/hbase-connector/lib/jasper-compiler-5.5.23.jar:lib/hbase-connector/lib/jasper-runtime-5.5.23.jar:lib/hbase-connector/lib/java-xmlbuilder-0.4.jar:lib/hbase-connector/lib/javassist-3.24.0-GA.jar:lib/hbase-connector/lib/javax.activation-api-1.2.0.jar:lib/hbase-connector/lib/javax.inject-1.jar:lib/hbase-connector/lib/jaxb-api-2.3.1.jar:lib/hbase-connector/lib/jaxb-impl-2.2.3-1.jar:lib/hbase-connector/lib/jersey-client-1.9.jar:lib/hbase-connector/lib/jersey-core-1.9.jar:lib/hbase-connector/lib/jersey-guice-1.9.jar:lib/hbase-connector/lib/jersey-json-1.9.jar:lib/hbase-connector/lib/jersey-server-1.9.jar:lib/hbase-connector/lib/jets3t-0.9.0.jar:lib/hbase-connector/lib/jettison-1.1.jar:lib/hbase-connector/lib/jetty-6.1.26.jar:lib/hbase-connector/lib/jetty-sslengine-6.1.26.jar:lib/hbase-connector/lib/jetty-util-6.1.26.jar:lib/hbase-connector/lib/jsch-0.1.42.jar:lib/hbase-connector/lib/jsp-2.1-6.1.14.jar:lib/hbase-connector/lib/jsp-api-2.1-6.1.14.jar:lib/hbase-connector/lib/jsp-api-2.1.jar:lib/hbase-connector/lib/jsr305-1.3.9.jar:lib/hbase-connector/lib/junit-4.12.jar:lib/hbase-connector/lib/kryo-2.24.0.jar:lib/hbase-connector/lib/leveldbjni-all-1.8.jar:lib/hbase-connector/lib/log4j-1.2-api-2.12.1.jar:lib/hbase-connector/lib/log4j-api-2.12.1.jar:lib/hbase-connector/lib/log4j-core-2.12.1.jar:lib/hbase-connector/lib/log4j-slf4j-impl-2.12.1.jar:lib/hbase-connector/lib/lz4-java-1.6.0.jar:lib/hbase-connector/lib/metrics-core-2.2.0.jar:lib/hbase-connector/lib/metrics-core-3.1.2.jar:lib/hbase-connector/lib/minlog-1.2.jar:lib/hbase-connector/lib/mockito-core-2.21.0.jar:lib/hbase-connector/lib/netty-3.6.2.Final.jar:lib/hbase-connector/lib/netty-all-4.1.44.Final.jar:lib/hbase-connector/lib/objenesis-2.1.jar:lib/hbase-connector/lib/paranamer-2.7.jar:lib/hbase-connector/lib/powermock-api-mockito2-2.0.4.jar:lib/hbase-connector/lib/powermock-api-support-2.0.4.jar:lib/hbase-connector/lib/powermock-core-2.0.4.jar:lib/hbase-connector/lib/powermock-module-junit4-2.0.4.jar:lib/hbase-connector/lib/powermock-module-junit4-common-2.0.4.jar:lib/hbase-connector/lib/powermock-reflect-2.0.4.jar:lib/hbase-connector/lib/protobuf-java-2.5.0.jar:lib/hbase-connector/lib/reactive-streams-1.0.2.jar:lib/hbase-connector/lib/reflections-0.9.10.jar:lib/hbase-connector/lib/scala-compiler-2.11.12.jar:lib/hbase-connector/lib/scala-java8-compat_2.11-0.7.0.jar:lib/hbase-connector/lib/scala-library-2.11.12.jar:lib/hbase-connector/lib/scala-parser-combinators_2.11-1.1.1.jar:lib/hbase-connector/lib/scala-reflect-2.11.12.jar:lib/hbase-connector/lib/scala-xml_2.11-1.0.5.jar:lib/hbase-connector/lib/scopt_2.11-3.5.0.jar:lib/hbase-connector/lib/servlet-api-2.5-6.1.14.jar:lib/hbase-connector/lib/servlet-api-2.5.jar:lib/hbase-connector/lib/slf4j-api-1.7.15.jar:lib/hbase-connector/lib/snappy-java-1.1.4.jar:lib/hbase-connector/lib/spotbugs-annotations-3.1.9.jar:lib/hbase-connector/lib/ssl-config-core_2.11-0.3.7.jar:lib/hbase-connector/lib/xmlenc-0.52.jar:lib/hbase-connector/lib/xz-1.5.jar:lib/hbase-connector/lib/zookeeper-3.4.14.jar:lib/kafka-clients-0.11.0.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.47.jar:lib/postgresql-42.2.5.jar:resource-flinksql1.11-2.0.0-SNAPSHOT-jar-with-dependencies.jar:lib/flink-dist_2.11-1.11.2.jar:flink-conf.yaml::/etc/hadoop/conf.cloudera.yarn:/run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-auth.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-aws.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-azure-datalake.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-common-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-common.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-nfs.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-format-sources.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-format.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-avro.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-cascading.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-column.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-common.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-encoding.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-generator.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-hadoop.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-jackson.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-pig.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-protobuf.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-scala_2.10.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-scrooge_2.10.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-test-hadoop2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-thrift.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-tools.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-annotations-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-auth-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-aws-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-azure-datalake-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-common-2.6.0-cdh5.15.2-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-common-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-nfs-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/hue-plugins-3.9.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/junit-4.11.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/logredactor-1.0.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/netty-3.10.5.Final.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/slf4j-api-1.7.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/slf4j-log4j12.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/aws-java-sdk-bundle-1.11.134.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/azure-data-lake-store-sdk-2.2.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-beanutils-1.9.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/htrace-core4-4.0.1-incubating.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-nfs.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-2.6.0-cdh5.15.2-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-nfs-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-registry.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-api-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-client-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-common-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-registry-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-common-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-tests-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/spark-yarn-shuffle.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/spark-1.6.0-cdh5.15.2-yarn-shuffle.jar
2021-02-07 16:01:32,092 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2021-02-07 16:01:32,094 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2021-02-07 16:01:32,098 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - YARN daemon is running as: deploy Yarn client user obtainer: deploy
2021-02-07 16:01:32,103 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.port, 8891
2021-02-07 16:01:32,103 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.interval, 10 SECONDS
2021-02-07 16:01:32,103 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.jobName, flink
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.cluster-id, application_1612516048266_0657
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.groupingKey, task_instance_id=T_8058178175794012_20210207160121459_1
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.path.root, /flink/dev
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.class, org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.storageDir, hdfs:///flink/ha/
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-port, 8080-8090
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.savepoint.ignore-unclaimed-state, false
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: yarn.provided.lib.dirs, hdfs://nameservice1/tmp/flink/lib;hdfs://nameservice1/tmp/flink/plugins;
2021-02-07 16:01:32,104 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.application.program-args, -mode;remote;-fs;eyJmc1VybCI6Im5hbWVzZXJ2aWNlMSIsIm5hbWVOb2RlcyI6WyJjZGgtZGV2LW5vZGUtMTIwOjgwMjAiLCJjZGguZHR3YXZlLnNpdC5sb2NhbDo4MDIwIl0sIm93bmVyVXNlck5hbWUiOiJhZG1pbiIsInZlbmRvck5hbWUiOiJDREgifQ==;-sqlpath;hdfs://nameservice1/shuxi/demo/dev/flink-1612684885180.sql
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.randomJobNameSuffix, false
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
2021-02-07 16:01:32,105 WARN  org.apache.flink.configuration.GlobalConfiguration           [] - Error while trying to split key and value in configuration file /data1/yarn/nm/usercache/deploy/appcache/application_1612516048266_0657/container_e111_1612516048266_0657_01_000001/flink-conf.yaml:18: "pipeline.classpaths: "
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1024m
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: classloader.resolve-order, parent-first
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: client.timeout, 300s
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.latency.interval, 2000
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.target, yarn-application
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1024m
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: table.sql-dialect, hive
2021-02-07 16:01:32,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-address, 0.0.0.0
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.deleteOnShutdown, false
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.quorum, 192.168.90.71:2181
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.attached, true
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.cluster.execution-mode, NORMAL
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability, zookeeper
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.shutdown-on-attached-exit, false
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.jars, file:/opt/plugins/CDH-5.14/stream/flink/resource/resource-flinksql1.11-2.0.0-SNAPSHOT-jar-with-dependencies.jar
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.host, 192.168.90.187
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.deployment.config-dir, /data/executor-proxy/codes//T_8058178175794012_20210207160121459_1_1
2021-02-07 16:01:32,106 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.yarn.log-config-file, /data/executor-proxy/codes/T_8058178175794012_20210207160121459_1_1/log4j.properties
2021-02-07 16:01:32,142 INFO  org.apache.flink.runtime.clusterframework.BootstrapTools     [] - Setting directories for temporary files to: /data1/yarn/nm/usercache/deploy/appcache/application_1612516048266_0657
2021-02-07 16:01:32,321 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Starting YarnApplicationClusterEntryPoint.
2021-02-07 16:01:32,337 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install default filesystem.
2021-02-07 16:01:32,389 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install security context.
2021-02-07 16:01:32,436 WARN  org.apache.hadoop.conf.Configuration                         [] - /run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER/core-site.xml:an attempt to override final parameter: hadoop.ssl.require.client.cert;  Ignoring.
2021-02-07 16:01:32,436 WARN  org.apache.hadoop.conf.Configuration                         [] - /run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER/core-site.xml:an attempt to override final parameter: hadoop.ssl.keystores.factory.class;  Ignoring.
2021-02-07 16:01:32,436 WARN  org.apache.hadoop.conf.Configuration                         [] - /run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER/core-site.xml:an attempt to override final parameter: hadoop.ssl.server.conf;  Ignoring.
2021-02-07 16:01:32,436 WARN  org.apache.hadoop.conf.Configuration                         [] - /run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER/core-site.xml:an attempt to override final parameter: hadoop.ssl.client.conf;  Ignoring.
2021-02-07 16:01:32,439 INFO  org.apache.flink.runtime.security.modules.HadoopModule       [] - Hadoop user set to deploy (auth:SIMPLE)
2021-02-07 16:01:32,446 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /data1/yarn/nm/usercache/deploy/appcache/application_1612516048266_0657/jaas-37217059690891305.conf.
2021-02-07 16:01:32,456 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Initializing cluster services.
2021-02-07 16:01:32,472 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address cdh-dev-node-119:0, bind address 0.0.0.0:0.
2021-02-07 16:01:33,074 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2021-02-07 16:01:33,102 INFO  akka.remote.Remoting                                         [] - Starting remoting
2021-02-07 16:01:33,276 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@cdh-dev-node-119:33622]
2021-02-07 16:01:33,489 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@cdh-dev-node-119:33622
2021-02-07 16:01:33,578 WARN  org.apache.hadoop.conf.Configuration                         [] - /run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER/core-site.xml:an attempt to override final parameter: hadoop.ssl.require.client.cert;  Ignoring.
2021-02-07 16:01:33,578 WARN  org.apache.hadoop.conf.Configuration                         [] - /run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER/core-site.xml:an attempt to override final parameter: hadoop.ssl.keystores.factory.class;  Ignoring.
2021-02-07 16:01:33,578 WARN  org.apache.hadoop.conf.Configuration                         [] - /run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER/core-site.xml:an attempt to override final parameter: hadoop.ssl.server.conf;  Ignoring.
2021-02-07 16:01:33,578 WARN  org.apache.hadoop.conf.Configuration                         [] - /run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER/core-site.xml:an attempt to override final parameter: hadoop.ssl.client.conf;  Ignoring.
2021-02-07 16:01:33,908 INFO  org.apache.flink.runtime.blob.FileSystemBlobStore            [] - Creating highly available BLOB storage directory at hdfs:/flink/ha/application_1612516048266_0657/blob
2021-02-07 16:01:34,072 INFO  org.apache.flink.runtime.util.ZooKeeperUtils                 [] - Enforcing default ACL for ZK connections
2021-02-07 16:01:34,072 INFO  org.apache.flink.runtime.util.ZooKeeperUtils                 [] - Using '/flink/dev/application_1612516048266_0657' as Zookeeper namespace.
2021-02-07 16:01:34,115 INFO  org.apache.flink.shaded.curator4.org.apache.curator.utils.Compatibility [] - Running in ZooKeeper 3.4.x compatibility mode
2021-02-07 16:01:34,115 INFO  org.apache.flink.shaded.curator4.org.apache.curator.utils.Compatibility [] - Using emulated InjectSessionExpiration
2021-02-07 16:01:34,145 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl [] - Starting
2021-02-07 16:01:34,153 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
2021-02-07 16:01:34,153 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:host.name=cdh-dev-node-119
2021-02-07 16:01:34,153 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.version=1.8.0_141
2021-02-07 16:01:34,153 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.vendor=Oracle Corporation
2021-02-07 16:01:34,153 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.home=/usr/java/jdk1.8.0_141-cloudera/jre
2021-02-07 16:01:34,153 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.class.path=:lib/commons-logging-1.1.3.jar:lib/commons-pool2-2.4.2.jar:lib/flink-avro-1.11.2-sql-jar.jar:lib/flink-connector-adb-jdbc_2.11-1.0-SNAPSHOT.jar:lib/flink-connector-jdbc_2.11-1.11.2.jar:lib/flink-connector-kafka-0.10_2.11-1.11.2.jar:lib/flink-connector-kafka-0.11_2.11-1.11.2.jar:lib/flink-connector-kafka-base_2.11-1.11.2.jar:lib/flink-connector-kudu_2.11-1.0-SNAPSHOT.jar:lib/flink-connector-redis_2.11-1.0-SNAPSHOT.jar:lib/flink-csv-1.11.2.jar:lib/flink-json-1.11.2.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-1.2.2_2.11-1.11.2.jar:lib/flink-sql-orc_2.11-1.11.2.jar:lib/flink-sql-parquet_2.11-1.11.2.jar:lib/flink-table-blink_2.11-1.11.2.jar:lib/flink-table_2.11-1.11.2.jar:lib/hbase-connector/flink-connector-hbase_2.11-1.11.1.jar:lib/hbase-connector/lib/akka-actor_2.11-2.5.21.jar:lib/hbase-connector/lib/akka-protobuf_2.11-2.5.21.jar:lib/hbase-connector/lib/akka-slf4j_2.11-2.5.21.jar:lib/hbase-connector/lib/akka-stream_2.11-2.5.21.jar:lib/hbase-connector/lib/aopalliance-1.0.jar:lib/hbase-connector/lib/asm-3.1.jar:lib/hbase-connector/lib/audience-annotations-0.5.0.jar:lib/hbase-connector/lib/avatica-core-1.16.0.jar:lib/hbase-connector/lib/avro-1.8.2.jar:lib/hbase-connector/lib/byte-buddy-1.8.15.jar:lib/hbase-connector/lib/byte-buddy-agent-1.8.15.jar:lib/hbase-connector/lib/chill-java-0.7.6.jar:lib/hbase-connector/lib/chill_2.11-0.7.6.jar:lib/hbase-connector/lib/commons-beanutils-1.8.3.jar:lib/hbase-connector/lib/commons-cli-1.3.1.jar:lib/hbase-connector/lib/commons-codec-1.10.jar:lib/hbase-connector/lib/commons-collections-3.2.2.jar:lib/hbase-connector/lib/commons-compiler-3.0.9.jar:lib/hbase-connector/lib/commons-compress-1.20.jar:lib/hbase-connector/lib/commons-configuration-1.7.jar:lib/hbase-connector/lib/commons-daemon-1.0.13.jar:lib/hbase-connector/lib/commons-digester-1.8.1.jar:lib/hbase-connector/lib/commons-el-1.0.jar:lib/hbase-connector/lib/commons-httpclient-3.1.jar:lib/hbase-connector/lib/commons-io-2.4.jar:lib/hbase-connector/lib/commons-lang-2.6.jar:lib/hbase-connector/lib/commons-lang3-3.3.2.jar:lib/hbase-connector/lib/commons-logging-1.1.3.jar:lib/hbase-connector/lib/commons-math-2.2.jar:lib/hbase-connector/lib/commons-math3-3.5.jar:lib/hbase-connector/lib/commons-net-3.1.jar:lib/hbase-connector/lib/config-1.3.0.jar:lib/hbase-connector/lib/curator-test-2.12.0.jar:lib/hbase-connector/lib/disruptor-3.4.2.jar:lib/hbase-connector/lib/findbugs-annotations-1.3.9-1.jar:lib/hbase-connector/lib/force-shading-1.11.1.jar:lib/hbase-connector/lib/grizzled-slf4j_2.11-1.3.2.jar:lib/hbase-connector/lib/guava-11.0.2.jar:lib/hbase-connector/lib/guice-3.0.jar:lib/hbase-connector/lib/guice-servlet-3.0.jar:lib/hbase-connector/lib/hadoop-annotations-2.4.1.jar:lib/hbase-connector/lib/hadoop-auth-2.4.1.jar:lib/hbase-connector/lib/hadoop-client-2.7.4.jar:lib/hbase-connector/lib/hadoop-common-2.4.1-tests.jar:lib/hbase-connector/lib/hadoop-common-2.4.1.jar:lib/hbase-connector/lib/hadoop-hdfs-2.4.1-tests.jar:lib/hbase-connector/lib/hadoop-hdfs-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-app-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-common-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-core-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-hs-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-jobclient-2.4.1-tests.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-jobclient-2.4.1.jar:lib/hbase-connector/lib/hadoop-mapreduce-client-shuffle-2.4.1.jar:lib/hbase-connector/lib/hadoop-minicluster-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-api-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-client-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-common-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-applicationhistoryservice-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-common-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-nodemanager-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-resourcemanager-2.4.1.jar:lib/hbase-connector/lib/hadoop-yarn-server-tests-2.4.1-tests.jar:lib/hbase-connector/lib/hadoop-yarn-server-web-proxy-2.4.1.jar:lib/hbase-connector/lib/hamcrest-all-1.3.jar:lib/hbase-connector/lib/hamcrest-core-1.3.jar:lib/hbase-connector/lib/hbase-annotations-1.4.3.jar:lib/hbase-connector/lib/hbase-client-1.4.3.jar:lib/hbase-connector/lib/hbase-common-1.4.3-tests.jar:lib/hbase-connector/lib/hbase-common-1.4.3.jar:lib/hbase-connector/lib/hbase-hadoop-compat-1.4.3-tests.jar:lib/hbase-connector/lib/hbase-hadoop-compat-1.4.3.jar:lib/hbase-connector/lib/hbase-hadoop2-compat-1.4.3-tests.jar:lib/hbase-connector/lib/hbase-hadoop2-compat-1.4.3.jar:lib/hbase-connector/lib/hbase-metrics-1.4.3.jar:lib/hbase-connector/lib/hbase-metrics-api-1.4.3.jar:lib/hbase-connector/lib/hbase-prefix-tree-1.4.3.jar:lib/hbase-connector/lib/hbase-procedure-1.4.3.jar:lib/hbase-connector/lib/hbase-protocol-1.4.3.jar:lib/hbase-connector/lib/hbase-server-1.4.3-tests.jar:lib/hbase-connector/lib/hbase-server-1.4.3.jar:lib/hbase-connector/lib/htrace-core-3.1.0-incubating.jar:lib/hbase-connector/lib/httpclient-4.5.3.jar:lib/hbase-connector/lib/httpcore-4.4.6.jar:lib/hbase-connector/lib/jackson-core-asl-1.8.8.jar:lib/hbase-connector/lib/jackson-jaxrs-1.9.13.jar:lib/hbase-connector/lib/jackson-mapper-asl-1.8.8.jar:lib/hbase-connector/lib/jackson-xc-1.8.3.jar:lib/hbase-connector/lib/jamon-runtime-2.4.1.jar:lib/hbase-connector/lib/janino-3.0.9.jar:lib/hbase-connector/lib/jasper-compiler-5.5.23.jar:lib/hbase-connector/lib/jasper-runtime-5.5.23.jar:lib/hbase-connector/lib/java-xmlbuilder-0.4.jar:lib/hbase-connector/lib/javassist-3.24.0-GA.jar:lib/hbase-connector/lib/javax.activation-api-1.2.0.jar:lib/hbase-connector/lib/javax.inject-1.jar:lib/hbase-connector/lib/jaxb-api-2.3.1.jar:lib/hbase-connector/lib/jaxb-impl-2.2.3-1.jar:lib/hbase-connector/lib/jersey-client-1.9.jar:lib/hbase-connector/lib/jersey-core-1.9.jar:lib/hbase-connector/lib/jersey-guice-1.9.jar:lib/hbase-connector/lib/jersey-json-1.9.jar:lib/hbase-connector/lib/jersey-server-1.9.jar:lib/hbase-connector/lib/jets3t-0.9.0.jar:lib/hbase-connector/lib/jettison-1.1.jar:lib/hbase-connector/lib/jetty-6.1.26.jar:lib/hbase-connector/lib/jetty-sslengine-6.1.26.jar:lib/hbase-connector/lib/jetty-util-6.1.26.jar:lib/hbase-connector/lib/jsch-0.1.42.jar:lib/hbase-connector/lib/jsp-2.1-6.1.14.jar:lib/hbase-connector/lib/jsp-api-2.1-6.1.14.jar:lib/hbase-connector/lib/jsp-api-2.1.jar:lib/hbase-connector/lib/jsr305-1.3.9.jar:lib/hbase-connector/lib/junit-4.12.jar:lib/hbase-connector/lib/kryo-2.24.0.jar:lib/hbase-connector/lib/leveldbjni-all-1.8.jar:lib/hbase-connector/lib/log4j-1.2-api-2.12.1.jar:lib/hbase-connector/lib/log4j-api-2.12.1.jar:lib/hbase-connector/lib/log4j-core-2.12.1.jar:lib/hbase-connector/lib/log4j-slf4j-impl-2.12.1.jar:lib/hbase-connector/lib/lz4-java-1.6.0.jar:lib/hbase-connector/lib/metrics-core-2.2.0.jar:lib/hbase-connector/lib/metrics-core-3.1.2.jar:lib/hbase-connector/lib/minlog-1.2.jar:lib/hbase-connector/lib/mockito-core-2.21.0.jar:lib/hbase-connector/lib/netty-3.6.2.Final.jar:lib/hbase-connector/lib/netty-all-4.1.44.Final.jar:lib/hbase-connector/lib/objenesis-2.1.jar:lib/hbase-connector/lib/paranamer-2.7.jar:lib/hbase-connector/lib/powermock-api-mockito2-2.0.4.jar:lib/hbase-connector/lib/powermock-api-support-2.0.4.jar:lib/hbase-connector/lib/powermock-core-2.0.4.jar:lib/hbase-connector/lib/powermock-module-junit4-2.0.4.jar:lib/hbase-connector/lib/powermock-module-junit4-common-2.0.4.jar:lib/hbase-connector/lib/powermock-reflect-2.0.4.jar:lib/hbase-connector/lib/protobuf-java-2.5.0.jar:lib/hbase-connector/lib/reactive-streams-1.0.2.jar:lib/hbase-connector/lib/reflections-0.9.10.jar:lib/hbase-connector/lib/scala-compiler-2.11.12.jar:lib/hbase-connector/lib/scala-java8-compat_2.11-0.7.0.jar:lib/hbase-connector/lib/scala-library-2.11.12.jar:lib/hbase-connector/lib/scala-parser-combinators_2.11-1.1.1.jar:lib/hbase-connector/lib/scala-reflect-2.11.12.jar:lib/hbase-connector/lib/scala-xml_2.11-1.0.5.jar:lib/hbase-connector/lib/scopt_2.11-3.5.0.jar:lib/hbase-connector/lib/servlet-api-2.5-6.1.14.jar:lib/hbase-connector/lib/servlet-api-2.5.jar:lib/hbase-connector/lib/slf4j-api-1.7.15.jar:lib/hbase-connector/lib/snappy-java-1.1.4.jar:lib/hbase-connector/lib/spotbugs-annotations-3.1.9.jar:lib/hbase-connector/lib/ssl-config-core_2.11-0.3.7.jar:lib/hbase-connector/lib/xmlenc-0.52.jar:lib/hbase-connector/lib/xz-1.5.jar:lib/hbase-connector/lib/zookeeper-3.4.14.jar:lib/kafka-clients-0.11.0.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.47.jar:lib/postgresql-42.2.5.jar:resource-flinksql1.11-2.0.0-SNAPSHOT-jar-with-dependencies.jar:lib/flink-dist_2.11-1.11.2.jar:flink-conf.yaml::/etc/hadoop/conf.cloudera.yarn:/run/cloudera-scm-agent/process/5045-yarn-NODEMANAGER:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-auth.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-aws.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-azure-datalake.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-common-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-common.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-nfs.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-format-sources.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-format.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-avro.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-cascading.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-column.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-common.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-encoding.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-generator.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-hadoop.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-jackson.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-pig.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-protobuf.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-scala_2.10.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-scrooge_2.10.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-test-hadoop2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-thrift.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/parquet-tools.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-annotations-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-auth-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-aws-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-azure-datalake-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-common-2.6.0-cdh5.15.2-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-common-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/hadoop-nfs-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/hue-plugins-3.9.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/junit-4.11.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/logredactor-1.0.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/netty-3.10.5.Final.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/slf4j-api-1.7.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/slf4j-log4j12.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/aws-java-sdk-bundle-1.11.134.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/azure-data-lake-store-sdk-2.2.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-beanutils-1.9.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/htrace-core4-4.0.1-incubating.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-nfs.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-2.6.0-cdh5.15.2-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/hadoop-hdfs-nfs-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-registry.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-api-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-client-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-common-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-registry-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-common-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-tests-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-2.6.0-cdh5.15.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/spark-yarn-shuffle.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop-yarn/lib/spark-1.6.0-cdh5.15.2-yarn-shuffle.jar
2021-02-07 16:01:34,154 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.library.path=:/opt/cloudera/parcels/CDH-5.15.2-1.cdh5.15.2.p0.3/lib/hadoop/lib/native:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2021-02-07 16:01:34,155 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.io.tmpdir=/tmp
2021-02-07 16:01:34,155 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.compiler=<NA>
2021-02-07 16:01:34,155 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:os.name=Linux
2021-02-07 16:01:34,155 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:os.arch=amd64
2021-02-07 16:01:34,155 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:os.version=3.10.0-514.el7.x86_64
2021-02-07 16:01:34,155 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:user.name=yarn
2021-02-07 16:01:34,155 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:user.home=/var/lib/hadoop-yarn
2021-02-07 16:01:34,155 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:user.dir=/data/dfs/yarn/nm/usercache/deploy/appcache/application_1612516048266_0657/container_e111_1612516048266_0657_01_000001
2021-02-07 16:01:34,156 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Initiating client connection, connectString=192.168.90.71:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator4.org.apache.curator.ConnectionState@70972170
2021-02-07 16:01:34,172 WARN  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - SASL configuration failed: javax.security.auth.login.LoginException: No JAAS configuration section named 'Client' was found in specified JAAS configuration file: '/data1/yarn/nm/usercache/deploy/appcache/application_1612516048266_0657/jaas-37217059690891305.conf'. Will continue connection to Zookeeper server without SASL authentication, if Zookeeper server allows it.
2021-02-07 16:01:34,172 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl [] - Default schema
2021-02-07 16:01:34,173 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - Opening socket connection to server cdh.dtwave.sit.local/192.168.90.71:2181
2021-02-07 16:01:34,173 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - Socket connection established to cdh.dtwave.sit.local/192.168.90.71:2181, initiating session
2021-02-07 16:01:34,174 ERROR org.apache.flink.shaded.curator4.org.apache.curator.ConnectionState [] - Authentication failed
2021-02-07 16:01:34,179 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - Session establishment complete on server cdh.dtwave.sit.local/192.168.90.71:2181, sessionid = 0x17748d9e15e784d, negotiated timeout = 60000
2021-02-07 16:01:34,180 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.state.ConnectionStateManager [] - State change: CONNECTED
2021-02-07 16:01:34,180 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Created BLOB server storage directory /data1/yarn/nm/usercache/deploy/appcache/application_1612516048266_0657/blobStore-712ec099-c1c8-4bb3-963c-e9168599fcb5
2021-02-07 16:01:34,184 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Started BLOB server at 0.0.0.0:37409 - max concurrent requests: 50 - max backlog: 1000
2021-02-07 16:01:34,251 INFO  org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter [] - Configured PrometheusPushGatewayReporter with {host:192.168.90.187, port:8891, jobName:flink, randomJobNameSuffix:false, deleteOnShutdown:false, groupingKey:{task_instance_id=T_8058178175794012_20210207160121459_1}}
2021-02-07 16:01:34,252 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - Periodically reporting metrics in intervals of 10 SECONDS for reporter promgateway of type org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.
2021-02-07 16:01:34,259 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address cdh-dev-node-119:0, bind address 0.0.0.0:0.
2021-02-07 16:01:34,274 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2021-02-07 16:01:34,277 INFO  akka.remote.Remoting                                         [] - Starting remoting
2021-02-07 16:01:34,288 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@cdh-dev-node-119:38134]
2021-02-07 16:01:34,318 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@cdh-dev-node-119:38134
2021-02-07 16:01:34,334 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2021-02-07 16:01:34,407 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Upload directory /tmp/flink-web-fda236c8-82d4-4a0a-a55a-055ad79bbb0c/flink-web-upload does not exist. 
2021-02-07 16:01:34,407 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Created directory /tmp/flink-web-fda236c8-82d4-4a0a-a55a-055ad79bbb0c/flink-web-upload for file uploads.
2021-02-07 16:01:34,442 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Starting rest endpoint.
2021-02-07 16:01:34,773 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component log file: /data1/yarn/container-logs/application_1612516048266_0657/container_e111_1612516048266_0657_01_000001/jobmanager.log
2021-02-07 16:01:34,773 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component stdout file: /data1/yarn/container-logs/application_1612516048266_0657/container_e111_1612516048266_0657_01_000001/jobmanager.out
2021-02-07 16:01:34,995 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Rest endpoint listening at cdh-dev-node-119:8080
2021-02-07 16:01:34,996 INFO  org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionService [] - Starting ZooKeeperLeaderElectionService ZooKeeperLeaderElectionService{leaderPath='/leader/rest_server_lock'}.
2021-02-07 16:01:35,022 WARN  org.apache.flink.shaded.curator4.org.apache.curator.utils.ZKPaths [] - The version of ZooKeeper being used doesn't support Container nodes. CreateMode.PERSISTENT will be used instead.
2021-02-07 16:01:35,028 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Web frontend listening at http://cdh-dev-node-119:8080.
2021-02-07 16:01:35,046 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction jvm overhead memory (102.400mb (107374184 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
2021-02-07 16:01:35,047 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction network memory (57.600mb (60397978 bytes)) is less than its min value 64.000mb (67108864 bytes), min value will be used instead
2021-02-07 16:01:35,057 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - http://cdh-dev-node-119:8080 was granted leadership with leaderSessionID=6ab709d2-17d3-4bfb-95e9-ab96055a8989
2021-02-07 16:01:35,096 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.yarn.YarnResourceManager at akka://flink/user/rpc/resourcemanager_0 .
2021-02-07 16:01:35,109 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.port, 8891
2021-02-07 16:01:35,109 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.interval, 10 SECONDS
2021-02-07 16:01:35,109 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2021-02-07 16:01:35,109 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.jobName, flink
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.cluster-id, application_1612516048266_0657
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.groupingKey, task_instance_id=T_8058178175794012_20210207160121459_1
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.path.root, /flink/dev
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.class, org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.storageDir, hdfs:///flink/ha/
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-port, 8080-8090
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.savepoint.ignore-unclaimed-state, false
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: yarn.provided.lib.dirs, hdfs://nameservice1/tmp/flink/lib;hdfs://nameservice1/tmp/flink/plugins;
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.application.program-args, -mode;remote;-fs;eyJmc1VybCI6Im5hbWVzZXJ2aWNlMSIsIm5hbWVOb2RlcyI6WyJjZGgtZGV2LW5vZGUtMTIwOjgwMjAiLCJjZGguZHR3YXZlLnNpdC5sb2NhbDo4MDIwIl0sIm93bmVyVXNlck5hbWUiOiJhZG1pbiIsInZlbmRvck5hbWUiOiJDREgifQ==;-sqlpath;hdfs://nameservice1/shuxi/demo/dev/flink-1612684885180.sql
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.randomJobNameSuffix, false
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
2021-02-07 16:01:35,110 WARN  org.apache.flink.configuration.GlobalConfiguration           [] - Error while trying to split key and value in configuration file /data1/yarn/nm/usercache/deploy/appcache/application_1612516048266_0657/container_e111_1612516048266_0657_01_000001/flink-conf.yaml:18: "pipeline.classpaths: "
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1024m
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: classloader.resolve-order, parent-first
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: client.timeout, 300s
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.latency.interval, 2000
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.target, yarn-application
2021-02-07 16:01:35,110 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1024m
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: table.sql-dialect, hive
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-address, 0.0.0.0
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.deleteOnShutdown, false
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.quorum, 192.168.90.71:2181
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.attached, true
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.cluster.execution-mode, NORMAL
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability, zookeeper
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.shutdown-on-attached-exit, false
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.jars, file:/opt/plugins/CDH-5.14/stream/flink/resource/resource-flinksql1.11-2.0.0-SNAPSHOT-jar-with-dependencies.jar
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.host, 192.168.90.187
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.deployment.config-dir, /data/executor-proxy/codes//T_8058178175794012_20210207160121459_1_1
2021-02-07 16:01:35,111 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.yarn.log-config-file, /data/executor-proxy/codes/T_8058178175794012_20210207160121459_1_1/log4j.properties
2021-02-07 16:01:35,133 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2021-02-07 16:01:35,134 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Cannot get scheduler resource types: This YARN version does not support 'getSchedulerResourceTypes'
2021-02-07 16:01:35,142 INFO  org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionService [] - Starting ZooKeeperLeaderElectionService ZooKeeperLeaderElectionService{leaderPath='/leader/dispatcher_lock'}.
2021-02-07 16:01:35,143 INFO  org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalService [] - Starting ZooKeeperLeaderRetrievalService /leader/resource_manager_lock.
2021-02-07 16:01:35,143 INFO  org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalService [] - Starting ZooKeeperLeaderRetrievalService /leader/dispatcher_lock.
2021-02-07 16:01:35,194 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Start SessionDispatcherLeaderProcess.
2021-02-07 16:01:35,199 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Recover all persisted job graphs.
2021-02-07 16:01:35,204 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Successfully recovered 0 persisted job graphs.
2021-02-07 16:01:35,217 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_1 .
2021-02-07 16:01:35,241 INFO  org.apache.flink.client.ClientUtils                          [] - Starting program (detached: false)
2021-02-07 16:01:35,270 INFO  com.dtwave.dipper.stream.plugin.flink.sql.FlinkSqlExecutor$  [] - Start to run flinksql executor with args:-mode,remote,-fs,eyJmc1VybCI6Im5hbWVzZXJ2aWNlMSIsIm5hbWVOb2RlcyI6WyJjZGgtZGV2LW5vZGUtMTIwOjgwMjAiLCJjZGguZHR3YXZlLnNpdC5sb2NhbDo4MDIwIl0sIm93bmVyVXNlck5hbWUiOiJhZG1pbiIsInZlbmRvck5hbWUiOiJDREgifQ==,-sqlpath,hdfs://nameservice1/shuxi/demo/dev/flink-1612684885180.sql
2021-02-07 16:01:35,271 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Recovered 0 containers from previous attempts ([]).
2021-02-07 16:01:35,271 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Register application master response does not contain scheduler resource types, use '$internal.yarn.resourcemanager.enable-vcore-matching'.
2021-02-07 16:01:35,271 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Container matching strategy: IGNORE_VCORE.
2021-02-07 16:01:35,275 INFO  org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl [] - Upper bound of the thread pool size is 500
2021-02-07 16:01:35,276 INFO  org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy [] - yarn.client.max-nodemanagers-proxies : 500
2021-02-07 16:01:35,276 INFO  org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionService [] - Starting ZooKeeperLeaderElectionService ZooKeeperLeaderElectionService{leaderPath='/leader/resource_manager_lock'}.
2021-02-07 16:01:35,298 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - ResourceManager akka.tcp://flink@cdh-dev-node-119:33622/user/rpc/resourcemanager_0 was granted leadership with fencing token b0895d493bd340c0028bf0bd03aa4379
2021-02-07 16:01:35,305 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl [] - Starting the SlotManager.
2021-02-07 16:01:35,485 INFO  com.dtwave.dipper.stream.plugin.flink.sql.FlinkSqlExecutor$  [] - executionSqlFromHdfs hdfs://nameservice1/shuxi/demo/dev/flink-1612684885180.sql
2021-02-07 16:01:36,622 DEBUG org.apache.calcite.sql.parser                                [] - Reduced `t1`.`blogger_id` = `t4`.`id`
2021-02-07 16:01:36,629 DEBUG org.apache.calcite.sql.parser                                [] - Reduced `t1`.`blogger_id` = `t4`.`id`
2021-02-07 16:01:36,907 DEBUG org.apache.calcite.sql2rel                                   [] - Plan after converting SqlNode to RelNode
LogicalProject(EXPR$0=[PROCTIME()])
  LogicalTableScan(table=[[__temp_table__]])

2021-02-07 16:01:36,945 DEBUG org.apache.calcite.sql2rel                                   [] - Plan after converting SqlNode to RelNode
LogicalProject(EXPR$0=[PROCTIME()])
  LogicalTableScan(table=[[__temp_table__]])

2021-02-07 16:01:37,008 DEBUG org.apache.calcite.sql2rel                                   [] - Plan after converting SqlNode to RelNode
LogicalProject(live_id=[$0], blogger_id=[$1], live_time=[$2], EXPR$3=[PROCTIME()])
  LogicalTableScan(table=[[__temp_table__]])

2021-02-07 16:01:37,055 DEBUG org.apache.calcite.sql2rel                                   [] - Plan after converting SqlNode to RelNode
LogicalProject(id=[$4], name=[$5], live_id=[$0], EXPR$3=[CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
  LogicalCorrelate(correlation=[$cor0], joinType=[inner], requiredColumns=[{1, 3}])
    LogicalProject(live_id=[$0], blogger_id=[$1], live_time=[$2], ts=[PROCTIME()])
      LogicalTableScan(table=[[default_catalog, default_database, tiktok_live]])
    LogicalFilter(condition=[=($cor0.blogger_id, $0)])
      LogicalSnapshot(period=[$cor0.ts])
        LogicalTableScan(table=[[default_catalog, default_database, tiktok_user]])

2021-02-07 16:01:37,324 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#31:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#30,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,325 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#29:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#28,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,325 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#27:LogicalCorrelate.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#21,right=HepRelVertex#26,correlation=$cor0,joinType=inner,requiredColumns={1, 3})
2021-02-07 16:01:37,325 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#20:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#19,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,325 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,327 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#25:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#24,condition==($0, $cor0.blogger_id))
2021-02-07 16:01:37,327 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#23:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#22,period=$cor0.ts)
2021-02-07 16:01:37,327 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,328 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#0: Apply rule [SimplifyFilterConditionRule:simplifySubQuery] to [rel#39:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#38,condition==($0, $cor0.blogger_id))]
2021-02-07 16:01:37,337 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#45:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#44,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,337 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#43:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#42,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,337 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#41:LogicalCorrelate.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#35,right=HepRelVertex#40,correlation=$cor0,joinType=inner,requiredColumns={1, 3})
2021-02-07 16:01:37,338 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#34:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#33,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,338 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,338 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#39:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#38,condition==($0, $cor0.blogger_id))
2021-02-07 16:01:37,338 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#37:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#36,period=$cor0.ts)
2021-02-07 16:01:37,338 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,339 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#59:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#58,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,340 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#57:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#56,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,340 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#55:LogicalCorrelate.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#49,right=HepRelVertex#54,correlation=$cor0,joinType=inner,requiredColumns={1, 3})
2021-02-07 16:01:37,340 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#48:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#47,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,340 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,340 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#53:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#52,condition==($0, $cor0.blogger_id))
2021-02-07 16:01:37,340 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#51:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#50,period=$cor0.ts)
2021-02-07 16:01:37,340 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,341 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#73:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#72,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,341 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#71:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#70,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,341 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#69:LogicalCorrelate.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#63,right=HepRelVertex#68,correlation=$cor0,joinType=inner,requiredColumns={1, 3})
2021-02-07 16:01:37,341 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#62:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#61,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,341 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,341 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#67:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#66,condition==($0, $cor0.blogger_id))
2021-02-07 16:01:37,341 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#65:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#64,period=$cor0.ts)
2021-02-07 16:01:37,341 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,344 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#1: Apply rule [LogicalCorrelateToJoinFromTemporalTableRuleWithFilter] to [rel#83:LogicalCorrelate.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#77,right=HepRelVertex#82,correlation=$cor0,joinType=inner,requiredColumns={1, 3}), rel#76:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#75,inputs=0..2,exprs=[PROCTIME()]), rel#81:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#80,condition==($0, $cor0.blogger_id)), rel#79:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#78,period=$cor0.ts)]
2021-02-07 16:01:37,347 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#1: Rule LogicalCorrelateToJoinFromTemporalTableRuleWithFilter arguments [rel#83:LogicalCorrelate.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#77,right=HepRelVertex#82,correlation=$cor0,joinType=inner,requiredColumns={1, 3}), rel#76:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#75,inputs=0..2,exprs=[PROCTIME()]), rel#81:LogicalFilter.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#80,condition==($0, $cor0.blogger_id)), rel#79:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#78,period=$cor0.ts)] produced rel#89:LogicalJoin#89
2021-02-07 16:01:37,348 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#87:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#86,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,348 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#85:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#84,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,349 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#90:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#77,right=HepRelVertex#80,condition==($1, $4),joinType=inner)
2021-02-07 16:01:37,349 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#76:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#75,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,349 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,349 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#79:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#78,period=$cor0.ts)
2021-02-07 16:01:37,349 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,350 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#102:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#101,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,350 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#100:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#99,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,350 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#98:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#94,right=HepRelVertex#97,condition==($1, $4),joinType=inner)
2021-02-07 16:01:37,350 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#93:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#92,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,350 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,350 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#96:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#95,period=$cor0.ts)
2021-02-07 16:01:37,350 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,369 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#2: Apply rule [SimplifyJoinConditionRule] to [rel#115:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#111,right=HepRelVertex#114,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,370 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#4: Apply rule [JoinPushExpressionsRule] to [rel#115:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#111,right=HepRelVertex#114,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,371 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#8: Apply rule [ReduceExpressionsRule(Project)] to [rel#110:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#109,inputs=0..2,exprs=[PROCTIME()])]
2021-02-07 16:01:37,392 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#9: Apply rule [ReduceExpressionsRule(Project)] to [rel#117:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#116,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])]
2021-02-07 16:01:37,403 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#10: Apply rule [ReduceExpressionsRule(Join)] to [rel#115:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#111,right=HepRelVertex#114,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,406 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#119:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#118,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,406 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#117:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#116,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,406 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#115:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#111,right=HepRelVertex#114,condition==($1, $4),joinType=inner)
2021-02-07 16:01:37,406 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#110:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#109,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,406 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,407 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#113:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#112,period=$cor0.ts)
2021-02-07 16:01:37,407 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,408 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#11: Apply rule [ReduceExpressionsRule(Project)] to [rel#123:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#122,inputs=0..2,exprs=[PROCTIME()])]
2021-02-07 16:01:37,408 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#12: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#128:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#124,right=HepRelVertex#127,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,409 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#13: Apply rule [SimplifyJoinConditionRule] to [rel#128:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#124,right=HepRelVertex#127,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,409 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#15: Apply rule [JoinPushExpressionsRule] to [rel#128:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#124,right=HepRelVertex#127,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,410 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#16: Apply rule [ReduceExpressionsRule(Join)] to [rel#128:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#124,right=HepRelVertex#127,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,410 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#17: Apply rule [ReduceExpressionsRule(Project)] to [rel#130:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#129,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])]
2021-02-07 16:01:37,411 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#132:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#131,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,411 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#130:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#129,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,411 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#128:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#124,right=HepRelVertex#127,condition==($1, $4),joinType=inner)
2021-02-07 16:01:37,411 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#123:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#122,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,411 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,411 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#126:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#125,period=$cor0.ts)
2021-02-07 16:01:37,411 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,412 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#145:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#144,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,412 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#143:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#142,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,412 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#141:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#137,right=HepRelVertex#140,condition==($1, $4),joinType=inner)
2021-02-07 16:01:37,412 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#136:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#135,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,412 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,412 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#139:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#138,period=$cor0.ts)
2021-02-07 16:01:37,412 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,413 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#157:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#156,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,413 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#155:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#154,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
2021-02-07 16:01:37,413 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#153:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=HepRelVertex#149,right=HepRelVertex#152,condition==($1, $4),joinType=inner)
2021-02-07 16:01:37,413 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#148:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#147,inputs=0..2,exprs=[PROCTIME()])
2021-02-07 16:01:37,413 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
2021-02-07 16:01:37,413 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#151:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=HepRelVertex#150,period=$cor0.ts)
2021-02-07 16:01:37,414 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
2021-02-07 16:01:37,495 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 1/1; PHASE = PRE_PROCESS_MDR; COST = {inf}
2021-02-07 16:01:37,495 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 2/1; PHASE = PRE_PROCESS; COST = {inf}
2021-02-07 16:01:37,495 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 3/1; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,496 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)] rels [#169]
2021-02-07 16:01:37,496 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#124: Apply rule [FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)] to [rel#169:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)]
2021-02-07 16:01:37,498 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#174 via FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,625 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#124 generated 1 successors: [rel#174:FlinkLogicalSink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#173,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)]
2021-02-07 16:01:37,626 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 4/2; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,626 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkProjectJoinTransposeRule] rels [#167,#165]
2021-02-07 16:01:37,626 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#100: Apply rule [FlinkProjectJoinTransposeRule] to [rel#167:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL]), rel#165:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#161,right=RelSubset#164,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,629 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#180 via FlinkProjectJoinTransposeRule
2021-02-07 16:01:37,631 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#100 generated 1 successors: [rel#180:LogicalProject#180]
2021-02-07 16:01:37,632 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 5/3; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,632 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkProjectJoinTransposeRule] rels [#185,#183]
2021-02-07 16:01:37,632 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#216: Apply rule [FlinkProjectJoinTransposeRule] to [rel#185:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#184,exprs=[$2, $3, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL]), rel#183:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#181,right=RelSubset#182,condition==($1, $2),joinType=inner)]
2021-02-07 16:01:37,632 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#216 generated 0 successors.
2021-02-07 16:01:37,632 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 6/4; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,633 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [ProjectToCalcRule] rels [#185]
2021-02-07 16:01:37,633 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#227: Apply rule [ProjectToCalcRule] to [rel#185:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#184,exprs=[$2, $3, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])]
2021-02-07 16:01:37,633 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#186 via ProjectToCalcRule
2021-02-07 16:01:37,634 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#227 generated 1 successors: [rel#186:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#184,expr#0..3={inputs},expr#4=10,expr#5=100,expr#6=RAND_INTEGER($t4, $t5),expr#7=CAST($t6):BIGINT NOT NULL,0=$t2,1=$t3,2=$t0,3=$t7)]
2021-02-07 16:01:37,635 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 7/5; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,635 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#186]
2021-02-07 16:01:37,635 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#244: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#186:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#184,expr#0..3={inputs},expr#4=10,expr#5=100,expr#6=RAND_INTEGER($t4, $t5),expr#7=CAST($t6):BIGINT NOT NULL,0=$t2,1=$t3,2=$t0,3=$t7)]
2021-02-07 16:01:37,636 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#188 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,723 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#244 generated 1 successors: [rel#188:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#187,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)]
2021-02-07 16:01:37,723 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 8/6; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,723 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [ProjectToCalcRule] rels [#167]
2021-02-07 16:01:37,723 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#111: Apply rule [ProjectToCalcRule] to [rel#167:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])]
2021-02-07 16:01:37,723 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#193 via ProjectToCalcRule
2021-02-07 16:01:37,724 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#111 generated 1 successors: [rel#193:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..5={inputs},expr#6=10,expr#7=100,expr#8=RAND_INTEGER($t6, $t7),expr#9=CAST($t8):BIGINT NOT NULL,0=$t4,1=$t5,2=$t0,3=$t9)]
2021-02-07 16:01:37,724 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 9/7; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,724 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#193]
2021-02-07 16:01:37,724 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#264: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#193:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,expr#0..5={inputs},expr#6=10,expr#7=100,expr#8=RAND_INTEGER($t6, $t7),expr#9=CAST($t8):BIGINT NOT NULL,0=$t4,1=$t5,2=$t0,3=$t9)]
2021-02-07 16:01:37,724 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#195 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,726 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#264 generated 1 successors: [rel#195:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#194,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)]
2021-02-07 16:01:37,726 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 10/8; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,726 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [SimplifyJoinConditionRule] rels [#183]
2021-02-07 16:01:37,726 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#204: Apply rule [SimplifyJoinConditionRule] to [rel#183:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#181,right=RelSubset#182,condition==($1, $2),joinType=inner)]
2021-02-07 16:01:37,726 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#204 generated 0 successors.
2021-02-07 16:01:37,726 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 11/9; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,727 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [SimplifyJoinConditionRule] rels [#165]
2021-02-07 16:01:37,727 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#88: Apply rule [SimplifyJoinConditionRule] to [rel#165:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#161,right=RelSubset#164,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,727 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#88 generated 0 successors.
2021-02-07 16:01:37,728 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 12/10; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,728 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkJoinPushExpressionsRule] rels [#183]
2021-02-07 16:01:37,728 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#206: Apply rule [FlinkJoinPushExpressionsRule] to [rel#183:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#181,right=RelSubset#182,condition==($1, $2),joinType=inner)]
2021-02-07 16:01:37,729 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#206 generated 0 successors.
2021-02-07 16:01:37,729 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 13/11; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,729 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkJoinPushExpressionsRule] rels [#165]
2021-02-07 16:01:37,729 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#90: Apply rule [FlinkJoinPushExpressionsRule] to [rel#165:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#161,right=RelSubset#164,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,729 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#90 generated 0 successors.
2021-02-07 16:01:37,729 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 14/12; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,729 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)] rels [#183]
2021-02-07 16:01:37,729 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#209: Apply rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)] to [rel#183:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#181,right=RelSubset#182,condition==($1, $2),joinType=inner)]
2021-02-07 16:01:37,730 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#202 via FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,770 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#209 generated 1 successors: [rel#202:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=RelSubset#200,right=RelSubset#201,condition==($1, $2),joinType=inner)]
2021-02-07 16:01:37,770 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 15/13; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,770 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)] rels [#165]
2021-02-07 16:01:37,770 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#93: Apply rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)] to [rel#165:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#161,right=RelSubset#164,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,771 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#205 via FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,771 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#93 generated 1 successors: [rel#205:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=RelSubset#203,right=RelSubset#204,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,771 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 16/14; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FilterJoinRule:FilterJoinRule:no-filter] rels [#183]
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#197: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#183:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#181,right=RelSubset#182,condition==($1, $2),joinType=inner)]
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#197 generated 0 successors.
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 17/15; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FilterJoinRule:FilterJoinRule:no-filter] rels [#165]
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#81: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#165:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#161,right=RelSubset#164,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#81 generated 0 successors.
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 18/16; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkJoinPushExpressionsRule] rels [#202]
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#288: Apply rule [FlinkJoinPushExpressionsRule] to [rel#202:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=RelSubset#200,right=RelSubset#201,condition==($1, $2),joinType=inner)]
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#288 generated 0 successors.
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 19/17; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkJoinPushExpressionsRule] rels [#205]
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#301: Apply rule [FlinkJoinPushExpressionsRule] to [rel#205:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=RelSubset#203,right=RelSubset#204,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,772 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#301 generated 0 successors.
2021-02-07 16:01:37,773 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 20/18; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,773 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FilterJoinRule:FilterJoinRule:no-filter] rels [#202]
2021-02-07 16:01:37,773 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#284: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#202:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=RelSubset#200,right=RelSubset#201,condition==($1, $2),joinType=inner)]
2021-02-07 16:01:37,773 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#284 generated 0 successors.
2021-02-07 16:01:37,773 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 21/19; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,773 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FilterJoinRule:FilterJoinRule:no-filter] rels [#205]
2021-02-07 16:01:37,773 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#297: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#205:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=RelSubset#203,right=RelSubset#204,condition==($1, $4),joinType=inner)]
2021-02-07 16:01:37,773 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#297 generated 0 successors.
2021-02-07 16:01:37,773 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 22/20; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,774 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalSnapshotConverter(in:NONE,out:LOGICAL)] rels [#163]
2021-02-07 16:01:37,774 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#72: Apply rule [FlinkLogicalSnapshotConverter(in:NONE,out:LOGICAL)] to [rel#163:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#162,period=$cor0.ts)]
2021-02-07 16:01:37,775 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#210 via FlinkLogicalSnapshotConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,814 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#72 generated 1 successors: [rel#210:FlinkLogicalSnapshot.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#208,period=$cor0.ts)]
2021-02-07 16:01:37,814 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 23/21; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,814 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [ProjectToCalcRule] rels [#160]
2021-02-07 16:01:37,814 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#43: Apply rule [ProjectToCalcRule] to [rel#160:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,inputs=0..2,exprs=[PROCTIME()])]
2021-02-07 16:01:37,815 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#211 via ProjectToCalcRule
2021-02-07 16:01:37,815 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#43 generated 1 successors: [rel#211:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,expr#0..2={inputs},expr#3=PROCTIME(),proj#0..3={exprs})]
2021-02-07 16:01:37,815 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 24/22; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,815 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#7]
2021-02-07 16:01:37,816 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#22: Apply rule [FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])]
2021-02-07 16:01:37,816 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#212 via FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,852 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#22 generated 1 successors: [rel#212:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)]
2021-02-07 16:01:37,852 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 25/23; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,852 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#211]
2021-02-07 16:01:37,852 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#315: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#211:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,expr#0..2={inputs},expr#3=PROCTIME(),proj#0..3={exprs})]
2021-02-07 16:01:37,852 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#214 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,865 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#315 generated 1 successors: [rel#214:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#213,select=live_id, blogger_id, live_time, PROCTIME() AS ts)]
2021-02-07 16:01:37,865 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 26/24; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,866 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [#13]
2021-02-07 16:01:37,866 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#59: Apply rule [FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])]
2021-02-07 16:01:37,866 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#215 via FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,907 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#59 generated 1 successors: [rel#215:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user],fields=id, name)]
2021-02-07 16:01:37,908 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 27/25; PHASE = OPTIMIZE; COST = {5.6E8 rows, 6.3E8 cpu, 1.01E10 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,908 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [ProjectToCalcRule] rels [#178]
2021-02-07 16:01:37,908 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#179: Apply rule [ProjectToCalcRule] to [rel#178:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#164,inputs=0..1)]
2021-02-07 16:01:37,908 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#217 via ProjectToCalcRule
2021-02-07 16:01:37,909 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#179 generated 1 successors: [rel#217:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#164,expr#0..1={inputs},proj#0..1={exprs})]
2021-02-07 16:01:37,909 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 28/26; PHASE = OPTIMIZE; COST = {5.6E8 rows, 6.3E8 cpu, 1.01E10 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,909 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#217]
2021-02-07 16:01:37,909 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#346: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#217:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#164,expr#0..1={inputs},proj#0..1={exprs})]
2021-02-07 16:01:37,909 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#218 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,910 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#346 generated 1 successors: [rel#218:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#204,select=id, name)]
2021-02-07 16:01:37,910 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 29/27; PHASE = OPTIMIZE; COST = {5.6E8 rows, 6.3E8 cpu, 1.01E10 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,910 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [ProjectToCalcRule] rels [#177]
2021-02-07 16:01:37,910 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#153: Apply rule [ProjectToCalcRule] to [rel#177:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#161,inputs=0..1)]
2021-02-07 16:01:37,911 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#219 via ProjectToCalcRule
2021-02-07 16:01:37,912 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#153 generated 1 successors: [rel#219:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#161,expr#0..3={inputs},proj#0..1={exprs})]
2021-02-07 16:01:37,912 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 30/28; PHASE = OPTIMIZE; COST = {5.6E8 rows, 6.3E8 cpu, 1.01E10 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,912 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#219]
2021-02-07 16:01:37,912 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#366: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#219:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#161,expr#0..3={inputs},proj#0..1={exprs})]
2021-02-07 16:01:37,912 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#220 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,914 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#366 generated 1 successors: [rel#220:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#203,select=live_id, blogger_id)]
2021-02-07 16:01:37,914 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 31/29; PHASE = OPTIMIZE; COST = {7.6E8 rows, 6.3E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,915 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [ProjectRemoveRule] rels [#178]
2021-02-07 16:01:37,915 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#173: Apply rule [ProjectRemoveRule] to [rel#178:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#164,inputs=0..1)]
2021-02-07 16:01:37,919 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#164 via ProjectRemoveRule
2021-02-07 16:01:37,919 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#173 generated 1 successors: [rel#164:Subset#3.NONE.any.None: 0.[NONE].[NONE]]
2021-02-07 16:01:37,919 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 32/30; PHASE = OPTIMIZE; COST = {6.6E8 rows, 6.3E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,919 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Skip match: rule [FlinkCalcMergeRule] rels [#217,#217]
2021-02-07 16:01:37,919 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Skip match: rule [ProjectMergeRule:force_mode] rels [#178,#178]
2021-02-07 16:01:37,919 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [ProjectMergeRule:force_mode] rels [#177,#160]
2021-02-07 16:01:37,919 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#143: Apply rule [ProjectMergeRule:force_mode] to [rel#177:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#161,inputs=0..1), rel#160:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,inputs=0..2,exprs=[PROCTIME()])]
2021-02-07 16:01:37,919 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#223 via ProjectMergeRule:force_mode
2021-02-07 16:01:37,920 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#143 generated 1 successors: [rel#223:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,inputs=0..1)]
2021-02-07 16:01:37,920 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 33/31; PHASE = OPTIMIZE; COST = {6.6E8 rows, 6.3E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,920 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [ProjectToCalcRule] rels [#223]
2021-02-07 16:01:37,920 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#459: Apply rule [ProjectToCalcRule] to [rel#223:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,inputs=0..1)]
2021-02-07 16:01:37,920 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#224 via ProjectToCalcRule
2021-02-07 16:01:37,921 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#459 generated 1 successors: [rel#224:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,expr#0..2={inputs},proj#0..1={exprs})]
2021-02-07 16:01:37,921 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 34/32; PHASE = OPTIMIZE; COST = {6.6E8 rows, 6.3E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,921 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [#224]
2021-02-07 16:01:37,921 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#476: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#224:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,expr#0..2={inputs},proj#0..1={exprs})]
2021-02-07 16:01:37,921 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#225 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
2021-02-07 16:01:37,923 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#476 generated 1 successors: [rel#225:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#213,select=live_id, blogger_id)]
2021-02-07 16:01:37,923 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 35/33; PHASE = OPTIMIZE; COST = {5.6E8 rows, 5.3E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,923 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Skip match: rule [ProjectCalcMergeRule] rels [#178,#217]
2021-02-07 16:01:37,923 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [ProjectCalcMergeRule] rels [#177,#211]
2021-02-07 16:01:37,923 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#318: Apply rule [ProjectCalcMergeRule] to [rel#177:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#161,inputs=0..1), rel#211:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,expr#0..2={inputs},expr#3=PROCTIME(),proj#0..3={exprs})]
2021-02-07 16:01:37,924 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#227 via ProjectCalcMergeRule
2021-02-07 16:01:37,924 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#318 generated 1 successors: [rel#227:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,expr#0..2={inputs},proj#0..1={exprs})]
2021-02-07 16:01:37,924 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 36/34; PHASE = OPTIMIZE; COST = {5.6E8 rows, 5.3E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,924 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Skip match: rule [FlinkCalcMergeRule] rels [#218,#218]
2021-02-07 16:01:37,924 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 37/1; PHASE = CLEANUP; COST = {5.6E8 rows, 5.3E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:37,947 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Cheapest plan:
FlinkLogicalSink(table=[default_catalog.default_database.tiktok_live_info], fields=[blogger_id, blogger_name, live_id, fans_num]): rowcount = 3.0E7, cumulative cost = {5.6E8 rows, 5.3E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}, id = 232
  FlinkLogicalCalc(select=[id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3]): rowcount = 3.0E7, cumulative cost = {5.3E8 rows, 5.0E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}, id = 231
    FlinkLogicalJoin(condition=[=($1, $2)], joinType=[inner]): rowcount = 3.0E7, cumulative cost = {5.0E8 rows, 5.0E8 cpu, 7.7E9 io, 0.0 network, 0.0 memory}, id = 230
      FlinkLogicalCalc(select=[live_id, blogger_id]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 228
        FlinkLogicalTableSourceScan(table=[[default_catalog, default_database, tiktok_live]], fields=[live_id, blogger_id, live_time]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 212
      FlinkLogicalSnapshot(period=[$cor0.ts]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 2.0E8 cpu, 3.2E9 io, 0.0 network, 0.0 memory}, id = 229
        FlinkLogicalTableSourceScan(table=[[default_catalog, default_database, tiktok_user]], fields=[id, name]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}, id = 215

2021-02-07 16:01:37,949 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Provenance:
rel#232:FlinkLogicalSink#232
  direct
    rel#174:FlinkLogicalSink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#173,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
      call#124 rule [FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)]
        rel#169:LogicalSink.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#168,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
          no parent
rel#231:FlinkLogicalCalc#231
  direct
    rel#188:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#187,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)
      call#244 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#186:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#184,expr#0..3={inputs},expr#4=10,expr#5=100,expr#6=RAND_INTEGER($t4, $t5),expr#7=CAST($t6):BIGINT NOT NULL,0=$t2,1=$t3,2=$t0,3=$t7)
          call#227 rule [ProjectToCalcRule]
            rel#185:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#184,exprs=[$2, $3, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
              call#100 rule [FlinkProjectJoinTransposeRule]
                rel#167:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#166,exprs=[$4, $5, $0, CAST(RAND_INTEGER(10, 100)):BIGINT NOT NULL])
                  no parent
                rel#165:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#161,right=RelSubset#164,condition==($1, $4),joinType=inner)
                  no parent
rel#230:FlinkLogicalJoin#230
  direct
    rel#202:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=RelSubset#200,right=RelSubset#204,condition==($1, $2),joinType=inner)
      call#209 rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)]
        rel#183:LogicalJoin.NONE.any.None: 0.[NONE].[NONE](left=RelSubset#181,right=RelSubset#164,condition==($1, $2),joinType=inner)
          call#100 rule [FlinkProjectJoinTransposeRule]
            rel#167 (see above)
            rel#165 (see above)
rel#228:FlinkLogicalCalc#228
  direct
    rel#225:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#213,select=live_id, blogger_id)
      call#476 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#224:LogicalCalc.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,expr#0..2={inputs},proj#0..1={exprs})
          call#459 rule [ProjectToCalcRule]
            rel#223:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,inputs=0..1)
              call#143 rule [ProjectMergeRule:force_mode]
                rel#177:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#161,inputs=0..1)
                  call#100 rule [FlinkProjectJoinTransposeRule]
                    rel#167 (see above)
                    rel#165 (see above)
                rel#160:LogicalProject.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#159,inputs=0..2,exprs=[PROCTIME()])
                  no parent
rel#212:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)
  call#22 rule [FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#7:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live])
      no parent
rel#229:FlinkLogicalSnapshot#229
  direct
    rel#210:FlinkLogicalSnapshot.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#208,period=$cor0.ts)
      call#72 rule [FlinkLogicalSnapshotConverter(in:NONE,out:LOGICAL)]
        rel#163:LogicalSnapshot.NONE.any.None: 0.[NONE].[NONE](input=RelSubset#162,period=$cor0.ts)
          no parent
rel#215:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user],fields=id, name)
  call#59 rule [FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#13:LogicalTableScan.NONE.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user])
      no parent

2021-02-07 16:01:37,976 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#244:FlinkLogicalSink.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#243,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:37,976 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#242:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#241,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)
2021-02-07 16:01:37,976 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#240:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=HepRelVertex#236,right=HepRelVertex#239,condition==($1, $2),joinType=inner)
2021-02-07 16:01:37,976 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#235:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#234,select=live_id, blogger_id)
2021-02-07 16:01:37,977 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#212:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)
2021-02-07 16:01:37,977 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#238:FlinkLogicalSnapshot.LOGICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#237,period=$cor0.ts)
2021-02-07 16:01:37,977 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#215:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user],fields=id, name)
2021-02-07 16:01:37,994 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 1/1; PHASE = PRE_PROCESS_MDR; COST = {inf}
2021-02-07 16:01:37,994 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 2/1; PHASE = PRE_PROCESS; COST = {inf}
2021-02-07 16:01:37,994 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 3/1; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:37,994 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#257]
2021-02-07 16:01:37,994 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#578: Apply rule [StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#257:FlinkLogicalSink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#255,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)]
2021-02-07 16:01:38,002 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#262 via StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-02-07 16:01:38,026 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#578 generated 1 successors: [rel#262:StreamExecSink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#261,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)]
2021-02-07 16:01:38,026 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 4/2; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:38,026 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#254]
2021-02-07 16:01:38,026 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#561: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#254:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#253,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)]
2021-02-07 16:01:38,029 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#264 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-02-07 16:01:38,105 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#561 generated 1 successors: [rel#264:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#263,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)]
2021-02-07 16:01:38,105 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 5/3; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:38,105 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [StreamExecSnapshotOnTableScanRule] rels [#252,#247,#250,#215]
2021-02-07 16:01:38,105 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#555: Apply rule [StreamExecSnapshotOnTableScanRule] to [rel#252:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=RelSubset#248,right=RelSubset#251,condition==($1, $2),joinType=inner), rel#247:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#246,select=live_id, blogger_id), rel#250:FlinkLogicalSnapshot.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#249,period=$cor0.ts), rel#215:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user],fields=id, name)]
2021-02-07 16:01:38,117 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#267 via StreamExecSnapshotOnTableScanRule
2021-02-07 16:01:38,205 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#555 generated 1 successors: [rel#267:StreamExecLookupJoin.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#266,table=default_catalog.default_database.tiktok_user,joinType=InnerJoin,async=false,lookup=id=blogger_id,select=live_id, blogger_id, id, name)]
2021-02-07 16:01:38,206 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 6/4; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:38,206 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#247]
2021-02-07 16:01:38,206 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#517: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#247:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#246,select=live_id, blogger_id)]
2021-02-07 16:01:38,208 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#269 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-02-07 16:01:38,211 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#517 generated 1 successors: [rel#269:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#268,select=live_id, blogger_id)]
2021-02-07 16:01:38,211 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 7/5; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:38,212 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#215]
2021-02-07 16:01:38,212 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#528: Apply rule [StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#215:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user],fields=id, name)]
2021-02-07 16:01:38,214 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#270 via StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-02-07 16:01:38,247 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#528 generated 1 successors: [rel#270:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user],fields=id, name)]
2021-02-07 16:01:38,247 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 8/6; PHASE = OPTIMIZE; COST = {inf}
2021-02-07 16:01:38,247 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Pop match: rule [StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [#212]
2021-02-07 16:01:38,247 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#506: Apply rule [StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#212:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)]
2021-02-07 16:01:38,247 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Transform to: rel#272 via StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
2021-02-07 16:01:38,258 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#506 generated 1 successors: [rel#272:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)]
2021-02-07 16:01:38,259 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 9/7; PHASE = OPTIMIZE; COST = {5.0E8 rows, 3.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:38,259 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4506383c; TICK = 10/1; PHASE = CLEANUP; COST = {5.0E8 rows, 3.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}
2021-02-07 16:01:38,280 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Cheapest plan:
StreamExecSink(table=[default_catalog.default_database.tiktok_live_info], fields=[blogger_id, blogger_name, live_id, fans_num]): rowcount = 1.0E8, cumulative cost = {5.0E8 rows, 3.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 276
  StreamExecCalc(select=[id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3]): rowcount = 1.0E8, cumulative cost = {4.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 275
    StreamExecLookupJoin(table=[default_catalog.default_database.tiktok_user], joinType=[InnerJoin], async=[false], lookup=[id=blogger_id], select=[live_id, blogger_id, id, name]): rowcount = 1.0E8, cumulative cost = {3.0E8 rows, 2.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 274
      StreamExecCalc(select=[live_id, blogger_id]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 273
        StreamExecTableSourceScan(table=[[default_catalog, default_database, tiktok_live]], fields=[live_id, blogger_id, live_time]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 2.8E9 io, 0.0 network, 0.0 memory}, id = 272

2021-02-07 16:01:38,280 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - Provenance:
rel#276:StreamExecSink#276
  direct
    rel#262:StreamExecSink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#261,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
      call#578 rule [StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#257:FlinkLogicalSink.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#255,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
          no parent
rel#275:StreamExecCalc#275
  direct
    rel#264:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#263,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)
      call#561 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#254:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#253,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)
          no parent
rel#274:StreamExecLookupJoin#274
  direct
    rel#267:StreamExecLookupJoin.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#266,table=default_catalog.default_database.tiktok_user,joinType=InnerJoin,async=false,lookup=id=blogger_id,select=live_id, blogger_id, id, name)
      call#555 rule [StreamExecSnapshotOnTableScanRule]
        rel#252:FlinkLogicalJoin.LOGICAL.any.None: 0.[NONE].[NONE](left=RelSubset#248,right=RelSubset#251,condition==($1, $2),joinType=inner)
          no parent
        rel#247:FlinkLogicalCalc.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#246,select=live_id, blogger_id)
          no parent
        rel#250:FlinkLogicalSnapshot.LOGICAL.any.None: 0.[NONE].[NONE](input=RelSubset#249,period=$cor0.ts)
          no parent
        rel#215:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_user],fields=id, name)
          no parent
rel#273:StreamExecCalc#273
  direct
    rel#269:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=RelSubset#268,select=live_id, blogger_id)
      call#517 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#247 (see above)
rel#272:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)
  call#506 rule [StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#212:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.[NONE].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)
      no parent

2021-02-07 16:01:38,299 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#591: Apply rule [MiniBatchIntervalInferRule] to [rel#312:StreamExecSink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#311,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)]
2021-02-07 16:01:38,302 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#592: Apply rule [MiniBatchIntervalInferRule] to [rel#310:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#309,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)]
2021-02-07 16:01:38,303 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#593: Apply rule [MiniBatchIntervalInferRule] to [rel#308:StreamExecLookupJoin.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#307,table=default_catalog.default_database.tiktok_user,joinType=InnerJoin,async=false,lookup=id=blogger_id,select=live_id, blogger_id, id, name)]
2021-02-07 16:01:38,303 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#594: Apply rule [MiniBatchIntervalInferRule] to [rel#306:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#305,select=live_id, blogger_id)]
2021-02-07 16:01:38,303 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - call#595: Apply rule [MiniBatchIntervalInferRule] to [rel#286:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)]
2021-02-07 16:01:38,303 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#312:StreamExecSink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#311,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:38,303 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#310:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#309,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)
2021-02-07 16:01:38,303 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#308:StreamExecLookupJoin.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#307,table=default_catalog.default_database.tiktok_user,joinType=InnerJoin,async=false,lookup=id=blogger_id,select=live_id, blogger_id, id, name)
2021-02-07 16:01:38,303 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#306:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#305,select=live_id, blogger_id)
2021-02-07 16:01:38,303 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#286:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)
2021-02-07 16:01:38,305 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#321:StreamExecSink.STREAM_PHYSICAL.any.None: 0.[NONE].[NONE](input=HepRelVertex#320,table=default_catalog.default_database.tiktok_live_info,fields=blogger_id, blogger_name, live_id, fans_num)
2021-02-07 16:01:38,305 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#319:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#318,select=id, name, live_id, CAST(RAND_INTEGER(10, 100)) AS EXPR$3)
2021-02-07 16:01:38,305 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#317:StreamExecLookupJoin.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#316,table=default_catalog.default_database.tiktok_user,joinType=InnerJoin,async=false,lookup=id=blogger_id,select=live_id, blogger_id, id, name)
2021-02-07 16:01:38,305 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#315:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.[I].[NONE](input=HepRelVertex#314,select=live_id, blogger_id)
2021-02-07 16:01:38,305 DEBUG org.apache.calcite.plan.RelOptPlanner                        [] - For final plan, using rel#286:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.[I].[NONE](table=[default_catalog, default_database, tiktok_live],fields=live_id, blogger_id, live_time)
2021-02-07 16:01:38,783 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Job 00000000000000000000000000000000 is submitted.
2021-02-07 16:01:38,783 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Submitting Job with JobId=00000000000000000000000000000000.
2021-02-07 16:01:39,643 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 00000000000000000000000000000000 (insert-into_default_catalog.default_database.tiktok_live_info).
2021-02-07 16:01:39,645 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 00000000000000000000000000000000 (insert-into_default_catalog.default_database.tiktok_live_info).
2021-02-07 16:01:39,680 INFO  org.apache.flink.runtime.jobmanager.ZooKeeperJobGraphStore   [] - Added JobGraph(jobId: 00000000000000000000000000000000) to ZooKeeper.
2021-02-07 16:01:39,720 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_2 .
2021-02-07 16:01:39,730 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job insert-into_default_catalog.default_database.tiktok_live_info (00000000000000000000000000000000).
2021-02-07 16:01:39,751 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.tiktok_live_info (00000000000000000000000000000000).
2021-02-07 16:01:39,794 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job insert-into_default_catalog.default_database.tiktok_live_info (00000000000000000000000000000000).
2021-02-07 16:01:39,794 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2021-02-07 16:01:39,815 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 pipelined regions in 0 ms
2021-02-07 16:01:39,826 INFO  org.apache.flink.runtime.util.ZooKeeperUtils                 [] - Initialized ZooKeeperCompletedCheckpointStore in '/checkpoints/00000000000000000000000000000000'.
2021-02-07 16:01:39,845 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2021-02-07 16:01:39,872 INFO  org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore [] - Recovering checkpoints from ZooKeeper.
2021-02-07 16:01:39,875 INFO  org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore [] - Found 0 checkpoints in ZooKeeper.
2021-02-07 16:01:39,876 INFO  org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore [] - Trying to fetch 0 checkpoints from storage.
2021-02-07 16:01:39,879 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@485a0260 for insert-into_default_catalog.default_database.tiktok_live_info (00000000000000000000000000000000).
2021-02-07 16:01:39,883 INFO  org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionService [] - Starting ZooKeeperLeaderElectionService ZooKeeperLeaderElectionService{leaderPath='/leader/00000000000000000000000000000000/job_manager_lock'}.
2021-02-07 16:01:39,899 INFO  org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl      [] - JobManager runner for job insert-into_default_catalog.default_database.tiktok_live_info (00000000000000000000000000000000) was granted leadership with session id 2bbe6bf7-d0fb-4b8c-a890-fee592cf6774 at akka.tcp://flink@cdh-dev-node-119:33622/user/rpc/jobmanager_2.
2021-02-07 16:01:39,913 INFO  org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalService [] - Starting ZooKeeperLeaderRetrievalService /leader/resource_manager_lock.
2021-02-07 16:01:39,913 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job insert-into_default_catalog.default_database.tiktok_live_info (00000000000000000000000000000000) under job master id a890fee592cf67742bbe6bf7d0fb4b8c.
2021-02-07 16:01:39,915 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.EagerSchedulingStrategy]
2021-02-07 16:01:39,916 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job insert-into_default_catalog.default_database.tiktok_live_info (00000000000000000000000000000000) switched from state CREATED to RUNNING.
2021-02-07 16:01:39,923 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[default_catalog, default_database, tiktok_live]], fields=[live_id, blogger_id, live_time]) -> Calc(select=[live_id, blogger_id]) -> LookupJoin(table=[default_catalog.default_database.tiktok_user], joinType=[InnerJoin], async=[false], lookup=[id=blogger_id], select=[live_id, blogger_id, id, name]) -> Calc(select=[id, name, live_id, CAST((10 RAND_INTEGER 100)) AS EXPR$3]) -> Sink: Sink(table=[default_catalog.default_database.tiktok_live_info], fields=[blogger_id, blogger_name, live_id, fans_num]) (1/1) (3a9a7b6eee33bae03c426e78a5c95dea) switched from CREATED to SCHEDULED.
2021-02-07 16:01:39,938 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{397f0efffe380363d01a19bb953a2dea}]
2021-02-07 16:01:39,946 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager akka.tcp://flink@cdh-dev-node-119:33622/user/rpc/resourcemanager_0(b0895d493bd340c0028bf0bd03aa4379)
2021-02-07 16:01:39,951 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2021-02-07 16:01:39,955 INFO  org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalService [] - Starting ZooKeeperLeaderRetrievalService /leader/00000000000000000000000000000000/job_manager_lock.
2021-02-07 16:01:39,955 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Registering job manager a890fee592cf67742bbe6bf7d0fb4b8c@akka.tcp://flink@cdh-dev-node-119:33622/user/rpc/jobmanager_2 for job 00000000000000000000000000000000.
2021-02-07 16:01:39,960 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Registered job manager a890fee592cf67742bbe6bf7d0fb4b8c@akka.tcp://flink@cdh-dev-node-119:33622/user/rpc/jobmanager_2 for job 00000000000000000000000000000000.
2021-02-07 16:01:39,963 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: b0895d493bd340c0028bf0bd03aa4379.
2021-02-07 16:01:39,963 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{397f0efffe380363d01a19bb953a2dea}] and profile ResourceProfile{UNKNOWN} from resource manager.
2021-02-07 16:01:39,964 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Request slot with profile ResourceProfile{UNKNOWN} for job 00000000000000000000000000000000 with allocation id ece3c1678f47f5192b8e20a155b74932.
2021-02-07 16:01:39,976 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Requesting new TaskExecutor container with resource WorkerResourceSpec {cpuCores=1.0, taskHeapSize=25.600mb (26843542 bytes), taskOffHeapSize=0 bytes, networkMemSize=64.000mb (67108864 bytes), managedMemSize=230.400mb (241591914 bytes)}. Number pending workers of this resource is 1.
2021-02-07 16:01:40,821 INFO  org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl        [] - Received new token for : cdh-dev-node-119:8041
2021-02-07 16:01:40,824 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Received 1 containers.
2021-02-07 16:01:40,828 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Received 1 containers with resource <memory:1024, vCores:1>, 1 pending container requests.
2021-02-07 16:01:40,833 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - TaskExecutor container_1612516048266_0657_01_000002 will be started on cdh-dev-node-119 with TaskExecutorProcessSpec {cpuCores=1.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.600mb (26843542 bytes), taskOffHeapSize=0 bytes, networkMemSize=64.000mb (67108864 bytes), managedMemorySize=230.400mb (241591914 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=192.000mb (201326592 bytes)}.
2021-02-07 16:01:40,864 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Creating container launch context for TaskManagers
2021-02-07 16:01:40,864 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Starting TaskManagers
2021-02-07 16:01:40,882 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Removing container request Capability[<memory:1024, vCores:1>]Priority[1].
2021-02-07 16:01:40,883 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Accepted 1 requested containers, returned 0 excess containers, 0 pending container requests of resource <memory:1024, vCores:1>.
2021-02-07 16:01:40,884 INFO  org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl [] - Processing Event EventType: START_CONTAINER for Container container_1612516048266_0657_01_000002
2021-02-07 16:01:40,885 INFO  org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy [] - Opening proxy : cdh-dev-node-119:8041
2021-02-07 16:01:45,448 INFO  org.apache.flink.yarn.YarnResourceManager                    [] - Registering TaskManager with ResourceID container_1612516048266_0657_01_000002 (akka.tcp://flink@cdh-dev-node-119:45825/user/rpc/taskmanager_0) at ResourceManager
2021-02-07 16:01:45,604 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[default_catalog, default_database, tiktok_live]], fields=[live_id, blogger_id, live_time]) -> Calc(select=[live_id, blogger_id]) -> LookupJoin(table=[default_catalog.default_database.tiktok_user], joinType=[InnerJoin], async=[false], lookup=[id=blogger_id], select=[live_id, blogger_id, id, name]) -> Calc(select=[id, name, live_id, CAST((10 RAND_INTEGER 100)) AS EXPR$3]) -> Sink: Sink(table=[default_catalog.default_database.tiktok_live_info], fields=[blogger_id, blogger_name, live_id, fans_num]) (1/1) (3a9a7b6eee33bae03c426e78a5c95dea) switched from SCHEDULED to DEPLOYING.
2021-02-07 16:01:45,604 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: TableSourceScan(table=[[default_catalog, default_database, tiktok_live]], fields=[live_id, blogger_id, live_time]) -> Calc(select=[live_id, blogger_id]) -> LookupJoin(table=[default_catalog.default_database.tiktok_user], joinType=[InnerJoin], async=[false], lookup=[id=blogger_id], select=[live_id, blogger_id, id, name]) -> Calc(select=[id, name, live_id, CAST((10 RAND_INTEGER 100)) AS EXPR$3]) -> Sink: Sink(table=[default_catalog.default_database.tiktok_live_info], fields=[blogger_id, blogger_name, live_id, fans_num]) (1/1) (attempt #0) to container_1612516048266_0657_01_000002 @ cdh-dev-node-119 (dataPort=45033)
2021-02-07 16:01:46,721 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[default_catalog, default_database, tiktok_live]], fields=[live_id, blogger_id, live_time]) -> Calc(select=[live_id, blogger_id]) -> LookupJoin(table=[default_catalog.default_database.tiktok_user], joinType=[InnerJoin], async=[false], lookup=[id=blogger_id], select=[live_id, blogger_id, id, name]) -> Calc(select=[id, name, live_id, CAST((10 RAND_INTEGER 100)) AS EXPR$3]) -> Sink: Sink(table=[default_catalog.default_database.tiktok_live_info], fields=[blogger_id, blogger_name, live_id, fans_num]) (1/1) (3a9a7b6eee33bae03c426e78a5c95dea) switched from DEPLOYING to RUNNING.